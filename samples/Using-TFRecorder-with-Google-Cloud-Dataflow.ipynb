{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Google Cloud DataFlow with TFRecorder\n",
    "\n",
    "This notebook demonstrates how to use TFRecorder with Google Cloud DataFlow to scale up to processing any size of dataset.\n",
    "    \n",
    "## Notebook Setup\n",
    "\n",
    "1. Please install TFRecorder with the command `python setup.py` from the repository root.\n",
    "\n",
    "2. Create a new GCS bucket the command with `gsutil mb gs://your/bucket/name/` and set the BUCKET= constant to that name.\n",
    "\n",
    "3. Copy the test images from the TFRutil repo to the new gcs bucket with the command `gsutil cp -r  ./tfrutil/test_data/images gs://<BUCKET_NAME/images`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tfrecorder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tfrecorder\n",
      "  File was already downloaded /home/jupyter/tensorflow-recorder/samples/tfrecorder-2.0-py3-none-any.whl\n",
      "Successfully downloaded tfrecorder\n"
     ]
    }
   ],
   "source": [
    "!pip download tfrecorder --no-deps\n",
    "!cp tfrecorder* /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET=\"gs://tfrecorder-output/\" # ADD YOUR BUCKET HERE, E.G. \"GS://MYBUCKET/\"\n",
    "PROJECT=\"jared-playground\" # ADD YOUR PROJECT NAME HERE\n",
    "REGION=\"us-central1\" # ADD A COMPUTE REGION HERE\n",
    "OUTPUT_PATH = \"results/\"\n",
    "TFRECORDER_WHEEL = \"/home/jupyter/tensorflow-recorder/samples/tfrecorder-2.0-py3-none-any.whl\" #UPDATE VERSION AS NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/jupyter/tensorflow-recorder/tfrecorder/test_data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tfrecorder/test_data/images/TEST/cat/cat-800x600-3.jpg'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image_uri'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update image_uri \n",
    "\n",
    "The image_uri column is currently pointing to the local file locations for each test image. We will change this path to the new GCS location below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_uri'] = df.image_uri.str.replace(\"tfrecorder/\", BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://tfrecorder-output/test_data/images/TEST/cat/cat-800x600-3.jpg'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image_uri'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TFRecorderAccessor' object has no attribute 'to_tfrecord'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-b1c0f4e41355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df.tensorflow.to_tfrecord(output_dir=BUCKET + OUTPUT_PATH,\n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mrunner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DataflowRunner\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROJECT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mregion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREGION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      tfrecorder_wheel=TFRECORDER_WHEEL)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TFRecorderAccessor' object has no attribute 'to_tfrecord'"
     ]
    }
   ],
   "source": [
    "df.tensorflow.to_tfr(output_dir=BUCKET + OUTPUT_PATH,\n",
    "                     runner=\"DataflowRunner\",\n",
    "                     project=PROJECT,\n",
    "                     region=REGION,\n",
    "                     tfrecorder_wheel=TFRECORDER_WHEEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it!\n",
    "\n",
    "As you can see, TFRecorder has taken the supplied CSV and transformed it into TFRecords, ready for consumption, along with the transform function"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
